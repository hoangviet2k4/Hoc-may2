# -*- coding: utf-8 -*-
"""heart-doan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fXfdfXN7g9ZEgRQFKx4paViCfm4ijngW
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# Import Data"""

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("heart_attack_prediction_dataset.csv")
df.head()

df.info()

df.describe()

df.isnull().sum()

"""# Phân tích và xử lí dữ liệu"""

df.columns

df['Heart Attack Risk'].value_counts()

df['Sex'].value_counts()

df["Sex"].value_counts().to_frame()
df["Sex"].value_counts(normalize=True).to_frame()
sns.countplot(data=df, x="Sex", hue="Heart Attack Risk",
palette="Blues");

df['Diet'].value_counts()

df["Diet"].value_counts().to_frame()
df["Diet"].value_counts(normalize=True).to_frame()
sns.countplot(data=df, x="Diet", hue="Heart Attack Risk",
palette="Blues");

#loại bỏ các cột không giúp ích trong việc dự đoán
df.drop(['Country', 'Continent', 'Diet', 'Hemisphere'], axis = 1, inplace = True)

df.head()

df.info()

df[['BP_Systolic', 'BP_Diastolic']] = df['Blood Pressure'].str.split('/', expand=True)

df['BP_Systolic'] = pd.to_numeric(df['BP_Systolic'])
df['BP_Diastolic'] = pd.to_numeric(df['BP_Diastolic'])
df = df.drop("Blood Pressure", axis = 1)

# Chuyển đổi dữ liệu
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Sex'] = le.fit_transform(df['Sex'])

df.dtypes

df.corr()['Heart Attack Risk'].sort_values(ascending=False)

plt.figure(figsize = (20,10))
sns.heatmap(df.corr(), cmap="viridis_r", annot=True)

"""- Ta thấy Heart Attack Risk có mối tương quan cao với BP_Sytolic và Diabetes.
- Nguy cơ đau tim không phụ thuộc nhiều vào Obesity.
- Uống rượu (Alcohol Consumption) và hút thuốc (Smoking) không phải là nguyên nhân chính gây nên đau tim.

# Train test split
"""

X = df.drop('Heart Attack Risk', axis=1)
y = df['Heart Attack Risk']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Support Vector Classifier"""

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report

svm = SVC()
param_grid = {
    'C' : [0.1, 1, 10],
    'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],
    'degree' : [2, 3, 4],
}
grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)
grid_search.fit(X_train, y_train)

best_params = grid_search.best_params_
best_score = grid_search.best_score_

print('Best Hyperparmeters:', best_params)
print('Best Cross-Validation Score:', best_score)

best_svm = SVC(**best_params)
best_svm.fit(X_train, y_train)

y_pred = best_svm.predict(X_test)

print('\nClasification Report on Test Set:')
print(classification_report(y_test, y_pred))

"""# So sánh với thư viện Sklearn"""

from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
svm_sklearn = SVC()
svm_sklearn.fit(X_train, y_train)

# Dự đoán tập kiểm tra
y_pred_sklearn = svm_sklearn.predict(X_test)

# Đánh giá mô hình sklearn
accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)
report_sklearn = classification_report(y_test, y_pred_sklearn)

print(f'Độ chính xác (sklearn): {accuracy_sklearn}')
print(f'Báo cáo phân loại (sklearn):\n{report_sklearn}')